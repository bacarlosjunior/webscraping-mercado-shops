# -*- coding: utf-8 -*-
"""Webscraping_Mercado_Shops.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gGz7w68f8rdgG_Uk93GSxWs8Av3ordp6
"""

# Base URL e número inicial da página
# Atualizar base_url de acordo com a página de produtos
# Utilizar o "_NoIndex_True" para começar na página incial
# modelo: base_url = 'https://www.itaqueraautopecas.com.br/lista/acessorios-veiculos/seguranca-veicular/_NoIndex_True'

# Alterar o nome do arquivo em "nome_do_arquivo.csv"
# modelo: file_name = 'dados_produtos.csv'

import re
import requests
from bs4 import BeautifulSoup
import csv
from google.colab import drive

# Montar o Google Drive
drive.mount('/content/drive')

# Base URL e número inicial da página
# Atualizar base_url de acordo com a página de produtos

base_url = 'https://www.anhaiamellodesmonte.com.br/lista/acessorios-veiculos/pecas-carros-caminhonetes/motor/motor-completo/_NoIndex_True'
page_number = 0
total_products = 0

# Caminho para salvar o arquivo CSV no seu Google Drive

# Alterar o nome do arquivo em "nome_do_arquivo.csv"

file_name = 'motores.csv'

csv_file_path = f'/content/drive/My Drive/{file_name}'

# Cria um arquivo CSV para escrever os dados
with open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:
    csv_writer = csv.writer(csv_file)
    csv_writer.writerow(['ID', 'Título', 'Preço', 'Link', 'Link da Imagem', 'Descrição', 'Disponibilidade', 'Estado', 'Marca'])

    while True:
        # Montar a URL da página atual
        url = f'{base_url}_Desde_{(page_number) * 48 + 1}'

        # Fazer a solicitação HTTP
        response = requests.get(url)
        if response.status_code != 200:
            print(f'Não foi possível acessar a página {url}')
            break

        # Analisar o conteúdo HTML
        soup = BeautifulSoup(response.text, 'html.parser')

        # Encontrar todos os elementos que representam os produtos na página atual
        products = soup.find_all('div', class_='ui-search-result__content-wrapper')

        if not products:
            print(f'Não há mais produtos na página {url}')
            print(f'Produtos coletados até agora: {total_products}')
            break

        for product in products:
            link = product.find('a', class_='ui-search-link')['href']
            match = re.search(r'/MLB-(\d+)-', link)
            product_id = match.group(1) if match else "ID não encontrado"

            #title_element = product.find('h2', class_='ui-search-item__title shops__item-title')
            #title = title_element.text.strip() if title_element else "Título não encontrado"

            title_element = product.find('a', class_='ui-search-link__title-card ui-search-link')
            title = title_element.get('title', 'Título não encontrado') if title_element else "Título não encontrado"

            price_element = product.find('span', class_='andes-money-amount__fraction')
            price = price_element.text.strip() if price_element else "Preço não encontrado"

            image_link = ''
            product_response = requests.get(link)
            if product_response.status_code == 200:
                product_soup = BeautifulSoup(product_response.text, 'html.parser')
                all_images = product_soup.find_all('img', class_='ui-pdp-image')
                additional_image_links = [img['src'] for img in all_images if img['src'].startswith('https')]
                image_link += ', ' + ', '.join(additional_image_links) if additional_image_links else ''

                description_element = product_soup.find('p', class_='ui-pdp-description__content')
                description = description_element.get_text(separator='\n').strip() if description_element else "Descrição não encontrada"

                state_element = product_soup.find('span', class_='ui-pdp-subtitle')
                estado = state_element.text.strip() if state_element else "Estado não encontrado"

                availability_element = product_soup.find('p', class_='ui-pdp-stock-information__title')
                availability = availability_element.text.strip() if availability_element else "in_stock"

                brand_element = product_soup.find('th', text='Marca')
                if brand_element:
                    brand = brand_element.find_next('span', class_='andes-table__column--value').text.strip()
                else:
                    brand = 'Marca não encontrada'

            csv_writer.writerow([product_id, title, price, link, image_link, description, availability, estado, brand])
            total_products += 1

        print(f'Produtos coletados até agora: {total_products}')

        page_number += 1

print('Arquivo CSV criado com sucesso em seu Google Drive.')

